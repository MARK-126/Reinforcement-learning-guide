# Matem√°ticas B√°sicas para Reinforcement Learning

## üéØ Objetivo de Esta Secci√≥n

Esta gu√≠a est√° dise√±ada para personas **sin conocimientos matem√°ticos previos** m√°s all√° de aritm√©tica b√°sica. Te prepararemos paso a paso para entender los conceptos matem√°ticos que necesitar√°s en Reinforcement Learning.

---

## 1. Notaci√≥n Matem√°tica B√°sica

Antes de empezar, familiar√≠c√©monos con s√≠mbolos que ver√°s frecuentemente:

| S√≠mbolo | Significado | Ejemplo |
|---------|-------------|---------|
| **‚àà** | "pertenece a" | x ‚àà S significa "x est√° en el conjunto S" |
| **Œ£** | "suma de" | Œ£·µ¢ x·µ¢ = x‚ÇÅ + x‚ÇÇ + x‚ÇÉ + ... |
| **‚àè** | "producto de" | ‚àè·µ¢ x·µ¢ = x‚ÇÅ √ó x‚ÇÇ √ó x‚ÇÉ √ó ... |
| **‚âà** | "aproximadamente igual" | 3.14159 ‚âà 3.14 |
| **‚â•, ‚â§** | "mayor o igual", "menor o igual" | x ‚â• 5 |
| **\|** | "tal que" | {x \| x > 0} = "conjunto de x tal que x es mayor que 0" |

### Ejemplo Pr√°ctico: Sumatoria (Œ£)

**Pregunta**: ¬øCu√°nto es Œ£·µ¢‚Çå‚ÇÅ¬≥ i¬≤?

**Soluci√≥n paso a paso**:
```
Œ£·µ¢‚Çå‚ÇÅ¬≥ i¬≤ = 1¬≤ + 2¬≤ + 3¬≤
         = 1 + 4 + 9
         = 14
```

**En Python**:
```python
suma = sum([i**2 for i in range(1, 4)])  # resultado: 14
```

---

## 2. Probabilidad desde Cero

### 2.1 ¬øQu√© es Probabilidad?

La **probabilidad** mide qu√© tan probable es que algo suceda. Va de 0 (imposible) a 1 (seguro).

**Ejemplos cotidianos**:
- Lanzar una moneda: P(cara) = 0.5 (50%)
- Tirar un dado: P(sacar 6) = 1/6 ‚âà 0.167 (16.7%)
- Lluvia ma√±ana: P(lluvia) = 0.3 (30%)

### 2.2 C√°lculo de Probabilidad B√°sica

```
P(evento) = n√∫mero de casos favorables / n√∫mero de casos totales
```

**Ejemplo**: Tienes una bolsa con 3 bolas rojas y 7 bolas azules.

```
P(roja) = 3/(3+7) = 3/10 = 0.3
P(azul) = 7/10 = 0.7
```

**En c√≥digo**:
```python
import random

# Simulaci√≥n de 1000 extracciones
bolsa = ['roja']*3 + ['azul']*7
extracciones = [random.choice(bolsa) for _ in range(1000)]
prob_roja = extracciones.count('roja') / 1000
print(f"P(roja) ‚âà {prob_roja}")  # Aproximadamente 0.3
```

### 2.3 Probabilidad Condicional

**Pregunta**: ¬øQu√© probabilidad hay de que llueva Y haga fr√≠o?

La **probabilidad condicional** P(A|B) se lee "probabilidad de A dado que B ocurri√≥".

```
P(A|B) = P(A y B) / P(B)
```

**Ejemplo real**:
- P(enfermo | test positivo) = probabilidad de estar enfermo dado que el test sali√≥ positivo

**Ejemplo con n√∫meros**:
```
P(lluvia) = 0.3
P(fr√≠o | lluvia) = 0.8  (80% de los d√≠as lluviosos hace fr√≠o)
P(lluvia Y fr√≠o) = P(lluvia) √ó P(fr√≠o | lluvia)
                 = 0.3 √ó 0.8 = 0.24
```

### 2.4 Eventos Independientes

Dos eventos son **independientes** si uno no afecta al otro.

**Ejemplos**:
- Lanzar dos monedas: el resultado de la primera no afecta la segunda
- P(cara‚ÇÅ Y cara‚ÇÇ) = P(cara‚ÇÅ) √ó P(cara‚ÇÇ) = 0.5 √ó 0.5 = 0.25

**En RL**: Las transiciones en un MDP son probabil√≠sticas pero independientes del pasado (propiedad de Markov).

---

## 3. Estad√≠stica Esencial

### 3.1 Media (Promedio)

La **media** es el valor promedio de un conjunto de n√∫meros.

```
media = (x‚ÇÅ + x‚ÇÇ + ... + x‚Çô) / n = (Œ£·µ¢ x·µ¢) / n
```

**Ejemplo**:
Recompensas en 5 episodios: [10, 15, 12, 18, 20]

```
media = (10 + 15 + 12 + 18 + 20) / 5 = 75 / 5 = 15
```

**En Python**:
```python
import numpy as np

recompensas = [10, 15, 12, 18, 20]
media = np.mean(recompensas)  # 15.0
```

### 3.2 Varianza y Desviaci√≥n Est√°ndar

La **varianza** mide qu√© tan dispersos est√°n los datos. La **desviaci√≥n est√°ndar** es su ra√≠z cuadrada (m√°s interpretable).

```
varianza = Œ£·µ¢ (x·µ¢ - media)¬≤ / n
desviaci√≥n_est√°ndar = ‚àövarianza
```

**Ejemplo**:
Recompensas: [10, 15, 12, 18, 20], media = 15

```
varianza = [(10-15)¬≤ + (15-15)¬≤ + (12-15)¬≤ + (18-15)¬≤ + (20-15)¬≤] / 5
         = [25 + 0 + 9 + 9 + 25] / 5
         = 68 / 5 = 13.6

desviaci√≥n_est√°ndar = ‚àö13.6 ‚âà 3.69
```

**Interpretaci√≥n**: Las recompensas t√≠picamente var√≠an ¬± 3.69 alrededor del promedio (15).

**En Python**:
```python
varianza = np.var(recompensas)  # 13.6
std = np.std(recompensas)       # 3.69
```

### 3.3 Valor Esperado (Expected Value)

El **valor esperado** E[X] es el promedio que esperar√≠as obtener si repitieras un experimento aleatorio muchas veces.

```
E[X] = Œ£·µ¢ x·µ¢ ¬∑ P(x·µ¢)
```

**Ejemplo**: Lanzas un dado. ¬øCu√°l es el valor esperado?

```
E[dado] = 1¬∑(1/6) + 2¬∑(1/6) + 3¬∑(1/6) + 4¬∑(1/6) + 5¬∑(1/6) + 6¬∑(1/6)
        = (1 + 2 + 3 + 4 + 5 + 6) / 6
        = 21 / 6 = 3.5
```

**En RL**: El valor de un estado V(s) es el retorno esperado (recompensa promedio futura).

**Simulaci√≥n en Python**:
```python
import random

# Simular 10000 lanzamientos de dado
lanzamientos = [random.randint(1, 6) for _ in range(10000)]
promedio = sum(lanzamientos) / len(lanzamientos)
print(f"E[dado] ‚âà {promedio}")  # Aproximadamente 3.5
```

---

## 4. Distribuciones de Probabilidad

### 4.1 Distribuci√≥n Uniforme

Todos los resultados tienen la **misma probabilidad**.

**Ejemplo**: Dado justo
```
P(1) = P(2) = P(3) = P(4) = P(5) = P(6) = 1/6
```

**En Python**:
```python
import matplotlib.pyplot as plt

resultados = [random.randint(1, 6) for _ in range(1000)]
plt.hist(resultados, bins=6, density=True)
plt.title("Distribuci√≥n Uniforme (Dado)")
plt.show()
```

### 4.2 Distribuci√≥n Normal (Gaussiana)

La famosa "curva de campana". La mayor√≠a de valores est√°n cerca de la media.

**Par√°metros**:
- **Œº (mu)**: media (centro de la campana)
- **œÉ (sigma)**: desviaci√≥n est√°ndar (ancho de la campana)

**Ejemplo**: Alturas humanas siguen una distribuci√≥n normal
```
Œº = 170 cm
œÉ = 10 cm
```

**En Python**:
```python
import numpy as np
import matplotlib.pyplot as plt

# Generar 1000 valores de una normal
valores = np.random.normal(loc=170, scale=10, size=1000)
plt.hist(valores, bins=30, density=True)
plt.title("Distribuci√≥n Normal (Œº=170, œÉ=10)")
plt.show()
```

### 4.3 Distribuci√≥n de Bernoulli

Experimento con solo **dos resultados**: √©xito (1) o fracaso (0).

**Ejemplo**: Lanzar una moneda
```
P(√©xito) = p = 0.5
P(fracaso) = 1-p = 0.5
```

**En RL**: Ambientes estoc√°sticos pueden usar Bernoulli para determinar transiciones.

**En Python**:
```python
# Lanzar moneda 10 veces
lanzamientos = np.random.binomial(n=1, p=0.5, size=10)
print(lanzamientos)  # Ej: [1, 0, 1, 1, 0, 0, 1, 1, 0, 1]
```

---

## 5. Operaciones con Funciones

### 5.1 M√°ximo y M√≠nimo

**max**: Encuentra el valor m√°s grande
**min**: Encuentra el valor m√°s peque√±o

```python
valores = [3, 7, 2, 9, 1]
maximo = max(valores)  # 9
minimo = min(valores)  # 1
```

### 5.2 argmax y argmin

**argmax**: Encuentra el **√≠ndice** (posici√≥n) del valor m√°ximo
**argmin**: Encuentra el **√≠ndice** del valor m√≠nimo

**Ejemplo**:
```python
import numpy as np

Q = [0.2, 0.8, 0.5, 0.9, 0.3]
#    ‚Üë    ‚Üë    ‚Üë    ‚Üë    ‚Üë
#    0    1    2    3    4  (√≠ndices)

mejor_accion = np.argmax(Q)  # 3 (posici√≥n del 0.9)
```

**En RL**: `argmax Q(s,a)` significa "selecciona la acci√≥n con mayor valor Q".

### 5.3 Funci√≥n Exponencial

La funci√≥n **exp(x) = eÀ£** donde e ‚âà 2.718 es la base del logaritmo natural.

**Propiedades importantes**:
```
exp(0) = 1
exp(1) ‚âà 2.718
exp(-‚àû) ‚Üí 0
exp(‚àû) ‚Üí ‚àû
```

**En Python**:
```python
import numpy as np

np.exp(0)   # 1.0
np.exp(1)   # 2.718...
np.exp(-5)  # 0.0067... (muy peque√±o)
```

**En RL**: Funci√≥n softmax usa exponenciales para convertir valores en probabilidades.

---

## 6. Conceptos Avanzados (Preparaci√≥n para RL)

### 6.1 Descuento Geom√©trico (Œ≥ - gamma)

En RL, recompensas futuras valen **menos** que recompensas presentes. Esto se modela con **descuento geom√©trico**.

```
Retorno total = r‚ÇÅ + Œ≥r‚ÇÇ + Œ≥¬≤r‚ÇÉ + Œ≥¬≥r‚ÇÑ + ...
```

Donde **Œ≥** (gamma) ‚àà [0, 1] es el factor de descuento.

**Ejemplo**:
- Recompensas: r‚ÇÅ=10, r‚ÇÇ=10, r‚ÇÉ=10
- Œ≥ = 0.9

```
Retorno = 10 + 0.9¬∑10 + 0.9¬≤¬∑10
        = 10 + 9 + 8.1
        = 27.1
```

**Interpretaci√≥n**:
- Œ≥ = 0: Solo importa recompensa inmediata (agente miope)
- Œ≥ = 1: Todas las recompensas valen igual (agente previsor infinito)
- Œ≥ = 0.9: Balance t√≠pico en RL

**En Python**:
```python
def calcular_retorno(recompensas, gamma):
    """Calcula retorno descontado"""
    retorno = 0
    for t, r in enumerate(recompensas):
        retorno += (gamma ** t) * r
    return retorno

recompensas = [10, 10, 10, 10, 10]
retorno = calcular_retorno(recompensas, gamma=0.9)
print(f"Retorno con Œ≥=0.9: {retorno:.2f}")  # 40.95
```

### 6.2 Series Geom√©tricas Infinitas

Si Œ≥ < 1, la suma infinita tiene un valor finito:

```
Œ£‚Çú‚Çå‚ÇÄ^‚àû Œ≥·µó = 1 + Œ≥ + Œ≥¬≤ + Œ≥¬≥ + ... = 1/(1-Œ≥)
```

**Ejemplo** (Œ≥ = 0.9):
```
1/(1-0.9) = 1/0.1 = 10
```

**En RL**: Si todas las recompensas son 1, el retorno m√°ximo es 1/(1-Œ≥).

### 6.3 Convergencia y L√≠mites

Una secuencia **converge** si se acerca cada vez m√°s a un valor l√≠mite.

**Ejemplo**:
```
Secuencia: 1, 0.5, 0.25, 0.125, 0.0625, ...
L√≠mite: 0
```

**En RL**: Algoritmos iterativos convergen cuando valores dejan de cambiar significativamente.

```python
def ha_convergido(valor_anterior, valor_nuevo, threshold=1e-6):
    """Verifica si un valor ha convergido"""
    return abs(valor_nuevo - valor_anterior) < threshold

# Ejemplo
V_anterior = 10.5
V_nuevo = 10.5000001
if ha_convergido(V_anterior, V_nuevo):
    print("¬°Convergi√≥!")
```

---

## 7. Ejercicios Pr√°cticos

### Ejercicio 1: Probabilidad B√°sica
Tienes una baraja de 52 cartas. ¬øCu√°l es la probabilidad de sacar un As?

<details>
<summary>Ver soluci√≥n</summary>

```
P(As) = 4/52 = 1/13 ‚âà 0.077 (7.7%)
```

Hay 4 ases en 52 cartas totales.
</details>

### Ejercicio 2: Valor Esperado
Un juego te da +$10 con probabilidad 0.6 y -$5 con probabilidad 0.4. ¬øCu√°l es la ganancia esperada?

<details>
<summary>Ver soluci√≥n</summary>

```
E[ganancia] = 10¬∑0.6 + (-5)¬∑0.4
            = 6 - 2
            = $4
```

En promedio, ganas $4 por juego.
</details>

### Ejercicio 3: Descuento
Recompensas: [5, 5, 5], Œ≥ = 0.8. Calcula el retorno total.

<details>
<summary>Ver soluci√≥n</summary>

```
G = 5 + 0.8¬∑5 + 0.8¬≤¬∑5
  = 5 + 4 + 3.2
  = 12.2
```
</details>

### Ejercicio 4: argmax
Q_values = [0.3, 0.7, 0.5, 0.9, 0.2]. ¬øCu√°l es argmax Q?

<details>
<summary>Ver soluci√≥n</summary>

```
argmax Q = 3
```

El valor m√°ximo es 0.9, que est√° en el √≠ndice 3.
</details>

---

## 8. Cheat Sheet: F√≥rmulas Esenciales

| Concepto | F√≥rmula | Uso en RL |
|----------|---------|-----------|
| **Probabilidad** | P(A) = casos_favorables / casos_totales | Transiciones estoc√°sticas |
| **Esperanza** | E[X] = Œ£ x·µ¢¬∑P(x·µ¢) | Valor de estados V(s) |
| **Media** | Œº = Œ£x·µ¢ / n | Promedio de recompensas |
| **Varianza** | œÉ¬≤ = Œ£(x·µ¢-Œº)¬≤ / n | Estabilidad del aprendizaje |
| **Descuento** | G = Œ£ Œ≥·µór‚Çú | Retorno total |
| **Serie geom√©trica** | Œ£Œ≥·µó = 1/(1-Œ≥) | Horizonte infinito |

---

## 9. Recursos Adicionales

### Videos Recomendados (Espa√±ol)
- [Khan Academy - Probabilidad](https://es.khanacademy.org/math/probability)
- [Khan Academy - Estad√≠stica](https://es.khanacademy.org/math/statistics-probability)

### Pr√°ctica Interactiva
- [Brilliant.org - Probability](https://brilliant.org/courses/probability/)
- [Coursera - Data Science Math Skills](https://www.coursera.org/learn/datasciencemathskills)

### Para Python
- [Python for Data Analysis](https://wesmckinney.com/book/)
- [NumPy Quickstart](https://numpy.org/doc/stable/user/quickstart.html)

---

## 10. Autoevaluaci√≥n

¬øEst√°s listo para continuar? Deber√≠as poder responder:

- [ ] ¬øQu√© significa P(A|B)?
- [ ] ¬øC√≥mo se calcula un valor esperado?
- [ ] ¬øQu√© hace argmax?
- [ ] ¬øPor qu√© usamos Œ≥ (descuento) en RL?
- [ ] ¬øCu√°ndo converge una serie geom√©trica?

Si respondiste todo, ¬°est√°s listo para [√Ålgebra Lineal](02_algebra_lineal.md)!

---

## Pr√≥ximos Pasos

1. **[√Ålgebra Lineal](02_algebra_lineal.md)** - Vectores y matrices
2. **[C√°lculo B√°sico](03_calculo_basico.md)** - Derivadas y gradientes
3. **[Python y NumPy](04_python_numpy.md)** - Programaci√≥n para RL
4. **[Optimizaci√≥n](05_conceptos_optimizacion.md)** - Encontrar mejores soluciones

¬°Sigue adelante! üöÄ
